
Working with Kafka (reading)


Files:
	•	amazon_reviews.csv: data base. 
	•	docker-compose.yml: defines and starts the Kafka environment (Kafka broker, Zookeeper, and Kafka UI) in Docker.
	•	producer.py: python script that reads reviews from a CSV file, updates the timestamp to the current time, and sends them to the Kafka topic at a fixed rate (10–15 messages per second).
	•	requirements.txt: lists Python dependencies required by producer.py (kafka-python).
	•	Dockerfile: builds a container image for the producer, installing dependencies and copying the producer script inside.
	•	build_producer.sh: shell script to build the Docker image for the Kafka producer.
	•	run_producer.sh: shell script to run the producer container in the same Docker network as Kafka, mounting the CSV file and passing environment variables.
	•	consumer.py: reads in Kafka and generates files tweets_dd_mm_yyyy_hh_mm.csv in the out.

Run:
	•	Start Kafka & Zookeeper: docker-compose up -d
	•	Build the consumer: ./build_consumer.sh
	•	Run the producer: ./run_producer.sh
	•	Run the consumer: ./run_consumer.sh
	•	Check consumer logs: docker logs -f tweets_consumer
	•	Verify output files: docker exec -it tweets_consumer ls -l /data/output
	•	Stopping the Services: docker stop tweets_producer tweets_consumer kafka zookeeper


